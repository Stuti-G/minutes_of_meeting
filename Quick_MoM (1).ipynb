{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC7YUnRKEeyk",
        "outputId": "1df60add-7150-4bbf-b34a-d03867bc660d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt =\"\"\"\n",
        "Chairman Wormsley (at the proper time and place, after taking the chair and striking the gavel on the table): This meeting of the CTAS County Commission will come to order. Clerk please call the role. (Ensure that a majority of the members are present.)\n",
        "\n",
        "Chairman Wormsley: Each of you has received the agenda. I will entertain a motion that the agenda be approved.\n",
        "\n",
        "Commissioner Brown: So moved.\n",
        "\n",
        "Commissioner Hobbs: Seconded\n",
        "\n",
        "Chairman Wormsley: It has been moved and seconded that the agenda be approved as received by the members. All those in favor signify by saying \"Aye\"?...Opposed by saying \"No\"?...The agenda is approved. You have received a copy of the minutes of the last meeting. Are there any corrections or additions to the meeting?\n",
        "\n",
        "Commissioner McCroskey: Mister Chairman, my name has been omitted from the Special Committee on Indigent Care.\n",
        "\n",
        "Chairman Wormsley: Thank you. If there are no objections, the minutes will be corrected to include the name of Commissioner McCroskey. Will the clerk please make this correction. Any further corrections? Seeing none, without objection the minutes will stand approved as read. (This is sort of a short cut way that is commonly used for approval of minutes and/or the agenda rather than requiring a motion and second.)\n",
        "\n",
        "Chairman Wormsley: Commissioner Adkins, the first item on the agenda is yours.\n",
        "\n",
        "Commissioner Adkins: Mister Chairman, I would like to make a motion to approve the resolution taking money from the Data Processing Reserve Account in the County Clerk's office and moving it to the equipment line to purchase a laptop computer.\n",
        "\n",
        "Commissioner Carmical: I second the motion.\n",
        "\n",
        "Chairman Wormsley: This resolution has a motion and second. Will the clerk please take the vote.\n",
        "\n",
        "Chairman Wormsley: The resolution passes. We will now take up old business. At our last meeting, Commissioner McKee, your motion to sell property near the airport was deferred to this meeting. You are recognized.\n",
        "\n",
        "Commissioner McKee: I move to withdraw that motion.\n",
        "\n",
        "Chairman Wormsley: Thank you so much, thats's really helps. Talk to you next monday.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "1rj2x2-OF7Xp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "response = openai.Completion.create(model=\"text-davinci-003\",prompt= \"Can you generate the Minute of Meeting in form of bullet points for the below transcript?\\n\"+prompt, temperature=0.7, max_tokens=256, top_p=1,frequency_penalty=0, presence_penalty=0)"
      ],
      "metadata": {
        "id": "_XxRS5MiFPZU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response['choices'][0][\"text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "smy3kK6oIQNA",
        "outputId": "ace74cee-e752-4be4-fd56-f2d4e6203a5d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nMinute of Meeting:\\n\\n- Meeting of the CTAS County Commission called to order \\n- Agenda approved \\n- Minutes of last meeting approved with correction to include name of Commissioner McCroskey \\n- Resolution to approve taking money from Data Processing Reserve Account in County Clerk's office and moving it to equipment line to purchase laptop computer passed \\n- Motion to sell property near airport withdrawn\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB66GVaVLPsA",
        "outputId": "daf07135-cd31-41dd-9415-028133137967"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20230314)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.65.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (9.1.0)\n",
            "Requirement already satisfied: tiktoken==0.3.1 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.3.1)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python==0.2.0->openai-whisper) (0.18.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.1->openai-whisper) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.1->openai-whisper) (2.27.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.12.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (16.0.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import whisper"
      ],
      "metadata": {
        "id": "hO12jxDcIY_k"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "path = '/content/Interview.mp4'\n",
        "\n",
        "subprocess.run('ffmpeg -i \"path/filename\".mp4 \"filename\".mp3',shell=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSS1odbhL-dB",
        "outputId": "485ac302-6ca6-4d32-cfba-f5af9187cfa2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args='ffmpeg -i \"path/filename\".mp4 \"filename\".mp3', returncode=1)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i \"/content/Interview.mp4\" \"audio_file.mp3\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxW2qUreQI-m",
        "outputId": "9affe23a-437e-428a-a962-fa1bf253ddd0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/Interview.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf54.61.104\n",
            "  Duration: 00:06:51.00, start: 0.000000, bitrate: 6797 kb/s\n",
            "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 6490 kb/s, 29.97 fps, 29.97 tbr, 11988 tbn, 59.94 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 144 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "    Stream #0:2(und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 144 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "    Stream #0:3(und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 1 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "    Stream #0:4(und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 1 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "Stream mapping:\n",
            "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, mp3, to 'audio_file.mp3':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    TSSE            : Lavf58.29.100\n",
            "    Stream #0:0(und): Audio: mp3 (libmp3lame), 48000 Hz, mono, fltp (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "      encoder         : Lavc58.54.100 libmp3lame\n",
            "size=    3211kB time=00:06:51.00 bitrate=  64.0kbits/s speed=54.7x    \n",
            "video:0kB audio:3211kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.010340%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"audio_file.mp3\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofrKxBK7LxWx",
        "outputId": "470ad000-f8b7-4f89-ebdc-7a3a5afa4e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcript = result[\"text\"]"
      ],
      "metadata": {
        "id": "D6K1QPXmQ2KP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "ysCPR2vwQ6A7",
        "outputId": "e140055c-921b-41f0-b38c-8bda767e901e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" This is in 2020 news. Now the presumptive Democratic nominee for president is holding a campaign rally for Battleground Florida tonight. Joe Biden joins us now. He's getting ready to rally in Tampa sort of virtually anyway. It is a video conference. Good to have you with us Mr. Biden. Well thank you for having me. I appreciate it. All right. So let's start off with what is still the all-consuming news here in Florida and everywhere else. That is coronavirus. It's impact on health and the economy. As you know our state is opening up very slowly. We're in phase one of our governor's plan here. But you've been critical recently of governor DeSantis and how he has handled this crisis. Are you still critical and do you think we should be reopening here in Florida? Well I think reopening should be in a phased position. We should make sure we do it and you know how we do it really matters. And in order to for we have to make sure that there's work protection available the PPP is available. We have to make sure there's testing available. We have to make sure there's clear rules and guidance about distancing and the like. And so in addition to that your governor's had great difficulty in being able to get out unemployment checks that because of the difficulty of the overwhelming number of claims but the inability to process those claims I'm told virtually 74 75 percent of people of file for unemployment have been able to get it. So but I think there's it's a false choice to say that you're going to have to choose between reopening and dealing with the virus. You have to do both. And as I said testing PPP to make sure people can be safe in their jobs if they go back at all and number three protect vulnerable populations and and not get into this false choice it's one or the other. Of that website for the unemployment has has been a huge issue here and as you know we are tourism based service based economy and and and people don't have money right now there is beginning to be more and more debate and we're going to hear more of it of by what authority does government have to shut down livelihoods like this and I'd like to know where you come down on that debate. Well look this is a crisis just like the pandemic of 1918 it's a crisis and the president has one responsibility to protect the well-being the physical well-being of the American people as he said he said I'm the commander in chief well he has come he's the commander and he has to take care of his troops and the fact of the matter is that you're not going to put people on a position where we're clear that you know we've already had over 74,000 deaths over a million 100,000 people more than anyone in the world any country in the world have been exposed to this virus and we have to get the material in place to be able to protect him so to suggest that there are no limitations on what people can do is it is not rational it's totally within the in the scope of government to be able to protect the American people. We listened in today the president's reelection campaign here in Florida had a press call they listed off how they're doubling down on staffers to campaign here on the ground in Florida the president says he's beginning to travel again he hopes to be campaigning here soon and as you know if he loses Florida he probably loses reelection so if you sir are unable to get out and reach voters you're you're doing a virtual rallied tonight but you're at home you're not in Florida how can you flip this battleground state if you can't get out and reach people. Well I hope we're going to be able to get out before too long depending on what precautions are being taken around the country and you're the largest battleground state in the nation and you know I think what we can expect is that it's going to be a really tightly contested election the polling data doesn't matter much now I'm ahead now but that's irrelevant right now and it's a very expensive state to campaign in but we're going to do everything on our power or whatever requirements were required to adhere to in terms of how we campaign to campaign for Florida. Look Florida needs a significant help in across the board the president's economic plan hadn't done very well you're a state that is in desperate need of some president understands science and the notion that we do have a thing called global warming seas arising a whole range of things are happening so there's a lot to there's a lot to compete on including education including the whole notion of global warming and dealing with this pandemic so we're going to be in the midst of that campaign and midst of that discussion and making our cases why we think we'd be better for Florida in the country then then Trump would. All right just very quickly I have to ask you about the news of the day general Flynn being the charges against him being dropped by the Department of Justice was the FBI wrong here did they try to set him up what's your reaction to this? Well it doesn't surprise me what the Justice Department is doing but I must tell you I just heard it 15 minutes before you just told me I don't know what the basis upon dropping it if there's a legitimate basis for dropping it and so I don't want to comment on because they don't know the facts in the rationale why they dropped it. And Tara Reid spoke out today with Megan Kelly saying she'd like to see you drop out of the race we'd like to get your response to that. Well look nothing ever happened with Tara Reid believing women means taking a woman's claim seriously when she steps forward and then vetting it looking into it and that's true as true in this case too women have a right to be heard and the press should rigorously investigate claims like these I'll always uphold that principle but in the end in every case the truth is what matters and in this case the truth is these claims are flat out false. All right sir I know you got a virtual rally to get to for Tampa we certainly appreciate your time hope to be able to welcome you to our state in person sometimes soon thank you very much mr. Biden. I hope so too look forward to seeing you thank you thank you.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-yqdc2PRiom",
        "outputId": "ceef089d-1092-42c8-95bb-b036b9152415"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.27.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.22.4)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.25.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.8)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (8.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Open AI Function da-vinci"
      ],
      "metadata": {
        "id": "rcIEJbV4RJbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MoM_generation(prompt):\n",
        "  response = openai.Completion.create(model=\"text-davinci-003\",\n",
        "                                      prompt= \"Can you generate the Minute of Meeting in form of bullet points for the below transcript?\\n\"+prompt, \n",
        "                                      temperature=0.7, \n",
        "                                      max_tokens=256, \n",
        "                                      top_p=1,\n",
        "                                      frequency_penalty=0, \n",
        "                                      presence_penalty=0)\n",
        "  return response['choices'][0]['text']"
      ],
      "metadata": {
        "id": "nS5JZ__lQQG3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final output"
      ],
      "metadata": {
        "id": "imKn5IzvRNbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = MoM_generation(transcript)"
      ],
      "metadata": {
        "id": "uN47DN9bQyWz"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "json_result = json.dumps('{\"result\": '+ result + '}')"
      ],
      "metadata": {
        "id": "Ffpv9-oSRCQO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.loads(json_result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a8XJrRPb8l_",
        "outputId": "75cc1e6b-4838-470c-9009-64a93c557327"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"result\": \n",
            "\n",
            "Minute of Meeting:\n",
            "- Joe Biden joined us to discuss coronavirus and its impact on health and the economy in Florida\n",
            "- He discussed reopening in a phased position and the need for protective measures such as PPP and testing\n",
            "- He mentioned issues with the website for unemployment and the debate over government shutdowns of livelihoods \n",
            "- He expressed that the president has a responsibility to protect the physical well-being of the American people\n",
            "- Biden expressed that the election will be tightly contested and the president's economic plan has not done well in Florida\n",
            "- He commented on the news of the day of the dropping of charges against general Flynn by the Department of Justice\n",
            "- He also responded to Tara Reid's call for him to drop out of the race \n",
            "- He concluded by expressing his hope to be able to welcome him to the state in person soon}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH1e14CQzWG1",
        "outputId": "3ce56986-a259-4897-f87b-552ef3bc26ee"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "# Example reference and summary strings\n",
        "reference = \"This is in 2020 news. Now the presumptive Democratic nominee for president is holding a campaign rally for Battleground Florida tonight. Joe Biden joins us now. He's getting ready to rally in Tampa sort of virtually anyway. It is a video conference. Good to have you with us Mr. Biden. Well thank you for having me. I appreciate it. All right. So let's start off with what is still the all-consuming news here in Florida and everywhere else. That is coronavirus. It's impact on health and the economy. As you know our state is opening up very slowly. We're in phase one of our governor's plan here. But you've been critical recently of governor DeSantis and how he has handled this crisis. Are you still critical and do you think we should be reopening here in Florida? Well I think reopening should be in a phased position. We should make sure we do it and you know how we do it really matters. And in order to for we have to make sure that there's work protection available the PPP is available. We have to make sure there's testing available. We have to make sure there's clear rules and guidance about distancing and the like. And so in addition to that your governor's had great difficulty in being able to get out unemployment checks that because of the difficulty of the overwhelming number of claims but the inability to process those claims I'm told virtually 74 75 percent of people of file for unemployment have been able to get it. So but I think there's it's a false choice to say that you're going to have to choose between reopening and dealing with the virus. You have to do both. And as I said testing PPP to make sure people can be safe in their jobs if they go back at all and number three protect vulnerable populations and and not get into this false choice it's one or the other. Of that website for the unemployment has has been a huge issue here and as you know we are tourism based service based economy and and and people don't have money right now there is beginning to be more and more debate and we're going to hear more of it of by what authority does government have to shut down livelihoods like this and I'd like to know where you come down on that debate. Well look this is a crisis just like the pandemic of 1918 it's a crisis and the president has one responsibility to protect the well-being the physical well-being of the American people as he said he said I'm the commander in chief well he has come he's the commander and he has to take care of his troops and the fact of the matter is that you're not going to put people on a position where we're clear that you know we've already had over 74,000 deaths over a million 100,000 people more than anyone in the world any country in the world have been exposed to this virus and we have to get the material in place to be able to protect him so to suggest that there are no limitations on what people can do is it is not rational it's totally within the in the scope of government to be able to protect the American people. We listened in today the president's reelection campaign here in Florida had a press call they listed off how they're doubling down on staffers to campaign here on the ground in Florida the president says he's beginning to travel again he hopes to be campaigning here soon and as you know if he loses Florida he probably loses reelection so if you sir are unable to get out and reach voters you're you're doing a virtual rallied tonight but you're at home you're not in Florida how can you flip this battleground state if you can't get out and reach people. Well I hope we're going to be able to get out before too long depending on what precautions are being taken around the country and you're the largest battleground state in the nation and you know I think what we can expect is that it's going to be a really tightly contested election the polling data doesn't matter much now I'm ahead now but that's irrelevant right now and it's a very expensive state to campaign in but we're going to do everything on our power or whatever requirements were required to adhere to in terms of how we campaign to campaign for Florida. Look Florida needs a significant help in across the board the president's economic plan hadn't done very well you're a state that is in desperate need of some president understands science and the notion that we do have a thing called global warming seas arising a whole range of things are happening so there's a lot to there's a lot to compete on including education including the whole notion of global warming and dealing with this pandemic so we're going to be in the midst of that campaign and midst of that discussion and making our cases why we think we'd be better for Florida in the country then then Trump would. All right just very quickly I have to ask you about the news of the day general Flynn being the charges against him being dropped by the Department of Justice was the FBI wrong here did they try to set him up what's your reaction to this? Well it doesn't surprise me what the Justice Department is doing but I must tell you I just heard it 15 minutes before you just told me I don't know what the basis upon dropping it if there's a legitimate basis for dropping it and so I don't want to comment on because they don't know the facts in the rationale why they dropped it. And Tara Reid spoke out today with Megan Kelly saying she'd like to see you drop out of the race we'd like to get your response to that. Well look nothing ever happened with Tara Reid believing women means taking a woman's claim seriously when she steps forward and then vetting it looking into it and that's true as true in this case too women have a right to be heard and the press should rigorously investigate claims like these I'll always uphold that principle but in the end in every case the truth is what matters and in this case the truth is these claims are flat out false. All right sir I know you got a virtual rally to get to for Tampa we certainly appreciate your time hope to be able to welcome you to our state in person sometimes soon thank you very much mr. Biden. I hope so too look forward to seeing you thank you thank you.\"\n",
        "summary = \"Joe Biden joined us to discuss coronavirus and its impact on health and the economy in Florida, He discussed reopening in a phased position and the need for protective measures such as PPP and testing, He mentioned issues with the website for unemployment and the debate over government shutdowns of livelihoods , He expressed that the president has a responsibility to protect the physical well-being of the American people,Biden expressed that the election will be tightly contested and the president's economic plan has not done well in Florida, He commented on the news of the day of the dropping of charges against general Flynn by the Department of Justice, He also responded to Tara Reid's call for him to drop out of the race , He concluded by expressing his hope to be able to welcome him to the state in person soon\"\n",
        "\n",
        "# Initialize Rouge object\n",
        "rouge = Rouge()\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "scores = rouge.get_scores(summary, reference)\n",
        "\n",
        "# Print scores\n",
        "print(scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E-SluyRysiR",
        "outputId": "058a2d0c-440b-43a0-e5b7-6b49764b827c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'rouge-1': {'r': 0.15777262180974477, 'p': 0.7391304347826086, 'f': 0.26003823801849163}, 'rouge-2': {'r': 0.04563894523326572, 'p': 0.34615384615384615, 'f': 0.08064515923196008}, 'rouge-l': {'r': 0.12529002320185614, 'p': 0.5869565217391305, 'f': 0.20650095312365419}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Open AI text-curie"
      ],
      "metadata": {
        "id": "jr_Hfe3Hshs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "KM0uHZ88b9iw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e63352b1-f837-4d90-aea4-5004a447b610"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MoM_generation1(prompt):\n",
        "  response = openai.Completion.create(model=\"text-curie-001\",\n",
        "                                      prompt= \"Can you generate the Minute of Meeting in form of bullet points for the below transcript?\\n\"+prompt, \n",
        "                                      temperature=0.7, \n",
        "                                      max_tokens=256, \n",
        "                                      top_p=1,\n",
        "                                      frequency_penalty=0, \n",
        "                                      presence_penalty=0)\n",
        "  return response['choices'][0]['text']"
      ],
      "metadata": {
        "id": "j8p0F0uburw6"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = MoM_generation1(transcript)\n",
        "import json\n",
        "json_result = json.dumps('{\"result\": '+ result + '}')\n",
        "print(json.loads(json_result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiHIMyYMwEZN",
        "outputId": "80841c72-ac31-4c2e-fdc6-a201d8ee32e2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"result\": \n",
            "\n",
            "-The coronavirus is still the all-consuming news in Florida and everywhere else\n",
            "-Governor DeSantis has been critical of the way Joe Biden has handled the crisis\n",
            "-Biden still critical of DeSantis, says reopening should be in a phased position and there are many other issues to compete on\n",
            "-Biden says the FBI was wrong when they tried to set up General Flynn\n",
            "-Biden doesn't want to comment on the charges because he doesn't know the rationale}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "# Example reference and summary strings\n",
        "reference = \"This is in 2020 news. Now the presumptive Democratic nominee for president is holding a campaign rally for Battleground Florida tonight. Joe Biden joins us now. He's getting ready to rally in Tampa sort of virtually anyway. It is a video conference. Good to have you with us Mr. Biden. Well thank you for having me. I appreciate it. All right. So let's start off with what is still the all-consuming news here in Florida and everywhere else. That is coronavirus. It's impact on health and the economy. As you know our state is opening up very slowly. We're in phase one of our governor's plan here. But you've been critical recently of governor DeSantis and how he has handled this crisis. Are you still critical and do you think we should be reopening here in Florida? Well I think reopening should be in a phased position. We should make sure we do it and you know how we do it really matters. And in order to for we have to make sure that there's work protection available the PPP is available. We have to make sure there's testing available. We have to make sure there's clear rules and guidance about distancing and the like. And so in addition to that your governor's had great difficulty in being able to get out unemployment checks that because of the difficulty of the overwhelming number of claims but the inability to process those claims I'm told virtually 74 75 percent of people of file for unemployment have been able to get it. So but I think there's it's a false choice to say that you're going to have to choose between reopening and dealing with the virus. You have to do both. And as I said testing PPP to make sure people can be safe in their jobs if they go back at all and number three protect vulnerable populations and and not get into this false choice it's one or the other. Of that website for the unemployment has has been a huge issue here and as you know we are tourism based service based economy and and and people don't have money right now there is beginning to be more and more debate and we're going to hear more of it of by what authority does government have to shut down livelihoods like this and I'd like to know where you come down on that debate. Well look this is a crisis just like the pandemic of 1918 it's a crisis and the president has one responsibility to protect the well-being the physical well-being of the American people as he said he said I'm the commander in chief well he has come he's the commander and he has to take care of his troops and the fact of the matter is that you're not going to put people on a position where we're clear that you know we've already had over 74,000 deaths over a million 100,000 people more than anyone in the world any country in the world have been exposed to this virus and we have to get the material in place to be able to protect him so to suggest that there are no limitations on what people can do is it is not rational it's totally within the in the scope of government to be able to protect the American people. We listened in today the president's reelection campaign here in Florida had a press call they listed off how they're doubling down on staffers to campaign here on the ground in Florida the president says he's beginning to travel again he hopes to be campaigning here soon and as you know if he loses Florida he probably loses reelection so if you sir are unable to get out and reach voters you're you're doing a virtual rallied tonight but you're at home you're not in Florida how can you flip this battleground state if you can't get out and reach people. Well I hope we're going to be able to get out before too long depending on what precautions are being taken around the country and you're the largest battleground state in the nation and you know I think what we can expect is that it's going to be a really tightly contested election the polling data doesn't matter much now I'm ahead now but that's irrelevant right now and it's a very expensive state to campaign in but we're going to do everything on our power or whatever requirements were required to adhere to in terms of how we campaign to campaign for Florida. Look Florida needs a significant help in across the board the president's economic plan hadn't done very well you're a state that is in desperate need of some president understands science and the notion that we do have a thing called global warming seas arising a whole range of things are happening so there's a lot to there's a lot to compete on including education including the whole notion of global warming and dealing with this pandemic so we're going to be in the midst of that campaign and midst of that discussion and making our cases why we think we'd be better for Florida in the country then then Trump would. All right just very quickly I have to ask you about the news of the day general Flynn being the charges against him being dropped by the Department of Justice was the FBI wrong here did they try to set him up what's your reaction to this? Well it doesn't surprise me what the Justice Department is doing but I must tell you I just heard it 15 minutes before you just told me I don't know what the basis upon dropping it if there's a legitimate basis for dropping it and so I don't want to comment on because they don't know the facts in the rationale why they dropped it. And Tara Reid spoke out today with Megan Kelly saying she'd like to see you drop out of the race we'd like to get your response to that. Well look nothing ever happened with Tara Reid believing women means taking a woman's claim seriously when she steps forward and then vetting it looking into it and that's true as true in this case too women have a right to be heard and the press should rigorously investigate claims like these I'll always uphold that principle but in the end in every case the truth is what matters and in this case the truth is these claims are flat out false. All right sir I know you got a virtual rally to get to for Tampa we certainly appreciate your time hope to be able to welcome you to our state in person sometimes soon thank you very much mr. Biden. I hope so too look forward to seeing you thank you thank you.\"\n",
        "summary = \"The coronavirus is still the all-consuming news in Florida and everywhere else, Governor DeSantis has been critical of the way Joe Biden has handled the crisis,Biden still critical of DeSantis, says reopening should be in a phased position and there are many other issues to compete on,Biden says the FBI was wrong when they tried to set up General Flynn,Biden doesn't want to comment on the charges because he doesn't know the rationale.\"\n",
        "# Initialize Rouge object\n",
        "rouge = Rouge()\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "scores = rouge.get_scores(summary, reference)\n",
        "\n",
        "# Print scores\n",
        "print(scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq7_ytyBxps7",
        "outputId": "bd124e31-2cef-46b6-89e5-5fb018ad61cc"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'rouge-1': {'r': 0.10672853828306264, 'p': 0.7931034482758621, 'f': 0.18813905721387916}, 'rouge-2': {'r': 0.030425963488843813, 'p': 0.4225352112676056, 'f': 0.05676442637216953}, 'rouge-l': {'r': 0.0951276102088167, 'p': 0.7068965517241379, 'f': 0.16768915946336796}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "\n",
        "def MoM_generation(prompt):\n",
        "    prompt = \"Can you generate the Minute of Meeting in form of bullet points for the below transcript?\\n\" + prompt\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "    input_chunks = torch.split(input_ids, 1000, dim=1)\n",
        "    output_chunks = []\n",
        "    for chunk in input_chunks:\n",
        "        output_ids = model.generate(chunk, max_length=2048, num_beams=1)\n",
        "        output_chunks.append(tokenizer.decode(output_ids[0], skip_special_tokens=True))\n",
        "    output = \" \".join(output_chunks)\n",
        "    return output.split(\"\\n\")[1:]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "hYzTntTW7Aff",
        "outputId": "0fbbc7ad-0233-45cb-d0ed-1b196bc80921"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-599f8df9f205>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't5-base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't5-base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"_from_config\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m         \u001b[0mrequires_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     \u001b[0mfailed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchecks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: \nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result1 = MoM_generation(transcript)\n",
        "import json\n",
        "json_result1 = json.dumps('{\"result1\": '+ result + '}')\n",
        "print(json.loads(json_result1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "KMKbotoO7IZv",
        "outputId": "b5edd16d-c5ed-49cc-bbd2-ff9185519b0a"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-b016320a6298>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMoM_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mjson_result1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{\"result1\": '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_result1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-60ec2dccd1c5>\u001b[0m in \u001b[0;36mMoM_generation\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"summarize: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msummary_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0;31m# if model is encoder decoder encoder_outputs are created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m             \u001b[0;31m# and added to `model_kwargs`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m             model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0m\u001b[1;32m   1287\u001b[0m                 \u001b[0minputs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_input_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0membed_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_positions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m         \u001b[0membed_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_pos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values_length)\u001b[0m\n\u001b[1;32m    138\u001b[0m         ).expand(bsz, -1)\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2208\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "# Example reference and summary strings\n",
        "reference = \"This is in 2020 news. Now the presumptive Democratic nominee for president is holding a campaign rally for Battleground Florida tonight. Joe Biden joins us now. He's getting ready to rally in Tampa sort of virtually anyway. It is a video conference. Good to have you with us Mr. Biden. Well thank you for having me. I appreciate it. All right. So let's start off with what is still the all-consuming news here in Florida and everywhere else. That is coronavirus. It's impact on health and the economy. As you know our state is opening up very slowly. We're in phase one of our governor's plan here. But you've been critical recently of governor DeSantis and how he has handled this crisis. Are you still critical and do you think we should be reopening here in Florida? Well I think reopening should be in a phased position. We should make sure we do it and you know how we do it really matters. And in order to for we have to make sure that there's work protection available the PPP is available. We have to make sure there's testing available. We have to make sure there's clear rules and guidance about distancing and the like. And so in addition to that your governor's had great difficulty in being able to get out unemployment checks that because of the difficulty of the overwhelming number of claims but the inability to process those claims I'm told virtually 74 75 percent of people of file for unemployment have been able to get it. So but I think there's it's a false choice to say that you're going to have to choose between reopening and dealing with the virus. You have to do both. And as I said testing PPP to make sure people can be safe in their jobs if they go back at all and number three protect vulnerable populations and and not get into this false choice it's one or the other. Of that website for the unemployment has has been a huge issue here and as you know we are tourism based service based economy and and and people don't have money right now there is beginning to be more and more debate and we're going to hear more of it of by what authority does government have to shut down livelihoods like this and I'd like to know where you come down on that debate. Well look this is a crisis just like the pandemic of 1918 it's a crisis and the president has one responsibility to protect the well-being the physical well-being of the American people as he said he said I'm the commander in chief well he has come he's the commander and he has to take care of his troops and the fact of the matter is that you're not going to put people on a position where we're clear that you know we've already had over 74,000 deaths over a million 100,000 people more than anyone in the world any country in the world have been exposed to this virus and we have to get the material in place to be able to protect him so to suggest that there are no limitations on what people can do is it is not rational it's totally within the in the scope of government to be able to protect the American people. We listened in today the president's reelection campaign here in Florida had a press call they listed off how they're doubling down on staffers to campaign here on the ground in Florida the president says he's beginning to travel again he hopes to be campaigning here soon and as you know if he loses Florida he probably loses reelection so if you sir are unable to get out and reach voters you're you're doing a virtual rallied tonight but you're at home you're not in Florida how can you flip this battleground state if you can't get out and reach people. Well I hope we're going to be able to get out before too long depending on what precautions are being taken around the country and you're the largest battleground state in the nation and you know I think what we can expect is that it's going to be a really tightly contested election the polling data doesn't matter much now I'm ahead now but that's irrelevant right now and it's a very expensive state to campaign in but we're going to do everything on our power or whatever requirements were required to adhere to in terms of how we campaign to campaign for Florida. Look Florida needs a significant help in across the board the president's economic plan hadn't done very well you're a state that is in desperate need of some president understands science and the notion that we do have a thing called global warming seas arising a whole range of things are happening so there's a lot to there's a lot to compete on including education including the whole notion of global warming and dealing with this pandemic so we're going to be in the midst of that campaign and midst of that discussion and making our cases why we think we'd be better for Florida in the country then then Trump would. All right just very quickly I have to ask you about the news of the day general Flynn being the charges against him being dropped by the Department of Justice was the FBI wrong here did they try to set him up what's your reaction to this? Well it doesn't surprise me what the Justice Department is doing but I must tell you I just heard it 15 minutes before you just told me I don't know what the basis upon dropping it if there's a legitimate basis for dropping it and so I don't want to comment on because they don't know the facts in the rationale why they dropped it. And Tara Reid spoke out today with Megan Kelly saying she'd like to see you drop out of the race we'd like to get your response to that. Well look nothing ever happened with Tara Reid believing women means taking a woman's claim seriously when she steps forward and then vetting it looking into it and that's true as true in this case too women have a right to be heard and the press should rigorously investigate claims like these I'll always uphold that principle but in the end in every case the truth is what matters and in this case the truth is these claims are flat out false. All right sir I know you got a virtual rally to get to for Tampa we certainly appreciate your time hope to be able to welcome you to our state in person sometimes soon thank you very much mr. Biden. I hope so too look forward to seeing you thank you thank you.\"\n",
        "summary1 = \"Joe Biden joined us to discuss coronavirus and its impact on health and the economy in Florida, He discussed reopening in a phased position and the need for protective measures such as PPP and testing, He mentioned issues with the website for unemployment and the debate over government shutdowns of livelihoods , He expressed that the president has a responsibility to protect the physical well-being of the American people,Biden expressed that the election will be tightly contested and the president's economic plan has not done well in Florida, He commented on the news of the day of the dropping of charges against general Flynn by the Department of Justice, He also responded to Tara Reid's call for him to drop out of the race , He concluded by expressing his hope to be able to welcome him to the state in person soon\"\n",
        "summary2 = \"The coronavirus is still the all-consuming news in Florida and everywhere else, Governor DeSantis has been critical of the way Joe Biden has handled the crisis,Biden still critical of DeSantis, says reopening should be in a phased position and there are many other issues to compete on,Biden says the FBI was wrong when they tried to set up General Flynn,Biden doesn't want to comment on the charges because he doesn't know the rationale.\"\n",
        "\n",
        "\n",
        "# Initialize Rouge object\n",
        "rouge = Rouge()\n",
        "\n",
        "# Calculate ROUGE scores for summary1\n",
        "scores1 = rouge.get_scores(summary1, reference)\n",
        "\n",
        "# Calculate ROUGE scores for summary2\n",
        "scores2 = rouge.get_scores(summary2, reference)\n",
        "\n",
        "# Compare ROUGE scores\n",
        "if scores1[0]['rouge-1']['f'] > scores2[0]['rouge-1']['f']:\n",
        "    print(\"Model 1 performed better on ROUGE-1.\")\n",
        "else:\n",
        "    print(\"Model 2 performed better on ROUGE-1.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9nzi_B61Clw",
        "outputId": "78a40cca-a976-4489-e7d8-559223c0a27b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 performed better on ROUGE-1.\n"
          ]
        }
      ]
    }
  ]
}